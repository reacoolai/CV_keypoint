<br>             
<br>
<div align="center">
<h1>ğŸ¤—å…³äºå…³é”®ç‚¹æ£€æµ‹çš„ä¸€äº›Demo</h1>
<br>
</div>
<br>
<br><br>

<img src='https://github.com/reacoolai/CV_keypoint/blob/main/img/3.png'>


<video src="https://github.com/reacoolai/CV_keypoint/blob/main/img/9169b1b2a975806b611d1ba2104b6abd_raw.mp4"></video>

## Usage 

### Prepraration 

```pypthon
git clone https://github.com/reacoolai/CV_keypoint
cd CV_keypoint
pip install -r requirements.txt
```

### Running 

```python
python gui.py
```



åŸºäºæ·±åº¦é¢„ä¼°æ¨¡å‹depth-anything-v2å’Œmeidapipeç»“åˆçš„æ£€æµ‹ç‚¹å¢å¼ºã€‚


<img src='https://github.com/reacoolai/CV_keypoint/blob/main/img/2.png'>

Depth-Anything-V2å®˜æ–¹æä¾›äº†4ç§æ¨¡å‹ï¼Œå…¶ä¸­åªæœ‰smallæ¨¡å‹çš„é€Ÿåº¦æ”¯æŒå®æ—¶è§†é¢‘çš„æ£€æµ‹ã€‚è¿™é‡Œé€‰æ‹©ä¸‹è½½smallæ¨¡å‹ã€‚åœ¨ Depth-Anything-V2ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªcheckpointså­˜æ”¾æ¨¡å‹ã€‚

| Model                   | Params | Checkpoint                                                   |
| ----------------------- | ------ | ------------------------------------------------------------ |
| Depth-Anything-V2-Small | 24.8M  | [Download](https://huggingface.co/depth-anything/Depth-Anything-V2-Small/resolve/main/depth_anything_v2_vits.pth?download=true) |
| Depth-Anything-V2-Base  | 97.5M  | [Download](https://huggingface.co/depth-anything/Depth-Anything-V2-Base/resolve/main/depth_anything_v2_vitb.pth?download=true) |
| Depth-Anything-V2-Large | 335.3M | [Download](https://huggingface.co/depth-anything/Depth-Anything-V2-Large/resolve/main/depth_anything_v2_vitl.pth?download=true) |
| Depth-Anything-V2-Giant | 1.3B   | Coming soon                                                  |

### Running

```python

python mouse_c.py		
```
RGBæ‘„åƒå¤´å›¾åƒè½¬æ¢ä¸ºæ·±åº¦æ‘„åƒå¤´çš„å›¾åƒ


```python

python rgb_to_rgbd.py
```
###  Running 
åœ¨å›¾åƒä¸Šè¿è¡Œè„šæœ¬
```python
python run.py \
  --encoder <vits | vitb | vitl | vitg> \
  --img-path <path> --outdir <outdir> \
  [--input-size <size>] [--pred-only] [--grayscale]
```
Options: é€‰é¡¹ï¼š

    --img-path: You can either 1) point it to an image directory storing all interested images, 2) point it to a single image, or 3) point it to a text file storing all image paths.
    --img-path ï¼šæ‚¨å¯ä»¥ 1) å°†å…¶æŒ‡å‘å­˜å‚¨æ‰€æœ‰æ„Ÿå…´è¶£å›¾åƒçš„å›¾åƒç›®å½•ï¼Œ2) å°†å…¶æŒ‡å‘å•ä¸ªå›¾åƒï¼Œæˆ– 3) å°†å…¶æŒ‡å‘å­˜å‚¨æ‰€æœ‰å›¾åƒè·¯å¾„çš„æ–‡æœ¬æ–‡ä»¶ã€‚
    --input-size (optional): By default, we use input size 518 for model inference. You can increase the size for even more fine-grained results.
    --input-size ï¼ˆå¯é€‰ï¼‰ï¼šé»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨è¾“å…¥å¤§å°518è¿›è¡Œæ¨¡å‹æ¨ç†ã€‚æ‚¨å¯ä»¥å¢åŠ å¤§å°ä»¥è·å¾—æ›´ç»†ç²’åº¦çš„ç»“æœã€‚
    --pred-only (optional): Only save the predicted depth map, without raw image.
    --pred-only (å¯é€‰): åªä¿å­˜é¢„æµ‹çš„æ·±åº¦å›¾ï¼Œä¸ä¿å­˜åŸå§‹å›¾åƒã€‚
    --grayscale (optional): Save the grayscale depth map, without applying color palette.
    --grayscale ï¼ˆå¯é€‰ï¼‰ï¼šä¿å­˜ç°åº¦æ·±åº¦å›¾ï¼Œä¸åº”ç”¨è°ƒè‰²æ¿ã€‚
è¿™æ˜¯ä¸€ä¸ªå°è¯•ï¼Œå¦‚æœæœ‰ç”¨åˆ°çš„åœ°æ–¹è¿˜æœ‰å¾ˆå¤§çš„ä¼˜åŒ–ç©ºé—´ï¼Œè¿™é‡Œåªæ˜¯å®ç°è¿™äº›æƒ³æ³•ğŸ¤—

å‚è€ƒé¡¹ç›®

| é¡¹ç›®              | github                                             | å®˜ç½‘                                    |
| ----------------- | -------------------------------------------------- | --------------------------------------- |
| mediapipe         | https://github.com/google-ai-edge/mediapipe        | https://developers.google.com/mediapipe |
| Depth Anything V2 | https://github.com/DepthAnything/Depth-Anything-V2 |                                         |



